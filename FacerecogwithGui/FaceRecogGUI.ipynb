{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window=tk.Tk()\n",
    "window.title(\"Face Recognition System\")\n",
    "\n",
    "#Get User Details\n",
    "l3=tk.Label(window,text=\"ID\", font=(\"Arial\",16))\n",
    "l3.grid(column=0,row=0)\n",
    "t3=tk.Entry(window,width=30,bd=5)\n",
    "t3.grid(column=5,row=0)\n",
    "\n",
    "\n",
    "l1=tk.Label(window,text=\"Name\", font=(\"Arial\",16))\n",
    "l1.grid(column=0,row=4)\n",
    "t1=tk.Entry(window,width=30,bd=5)\n",
    "t1.grid(column=5,row=4)\n",
    "\n",
    "\n",
    "l2=tk.Label(window,text=\"Designation\", font=(\"Arial\",16))\n",
    "l2.grid(column=0,row=6)\n",
    "t2=tk.Entry(window,width=30,bd=5)\n",
    "t2.grid(column=5,row=6)\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "facecascade= cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eyecascade=cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "\n",
    "#Generate Data\n",
    "def button():\n",
    "    if(t1.get()=='' or t2.get()=='' or t1.get().isdigit() ):\n",
    "         messagebox.showinfo(\"Please! Enter Name and Designation\")\n",
    "    else:\n",
    "        facecascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "        video_capture = cv2.VideoCapture(0)\n",
    "        id= t3.get()\n",
    "        img_id=1\n",
    "        name=t1.get()\n",
    "        designation=t2.get()\n",
    "       \n",
    "\n",
    "        while True:\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = video_capture.read()\n",
    "            roi_color=frame\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces =  facecascade.detectMultiScale(gray,1.2,5)\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi_color = frame[y:y+h, x:x+w]\n",
    "            img_id+=1\n",
    "            face=cv2.resize(roi_color,(200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            image_name=t1.get()\n",
    "            file_name_path =\"data/\"+name+\".\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "            cv2.imwrite(file_name_path,face)\n",
    "            cv2.putText(face,name,(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow(\"Cropped face\",face)\n",
    "            if cv2.waitKey(1)==13 or int(img_id==10) :\n",
    "                break\n",
    "        video_capture.release() \n",
    "        cv2.destroyAllWindows()\n",
    "        messagebox.showinfo(\"Samples are collected,Thank you!\")\n",
    "        faces,Ids = trainbutton('data')\n",
    "        recognizer.train(faces, np.array(Ids))\n",
    "        recognizer.save('trainner.yml')\n",
    "       \n",
    "                                                                                                  \n",
    "#tarin\n",
    "def trainbutton( data_dir):\n",
    "   # train_classifier(\"/FacerecogwithGui/data\")\n",
    "    \n",
    "    data_dir = \"data\";\n",
    "    path=[os.path.join(data_dir,f) for f in os.listdir(data_dir)]\n",
    "     #create empth face list\n",
    "    faceSamples=[]\n",
    "    #create empty ID list\n",
    "    Ids=[]\n",
    "    #now looping through all the image paths and loading the Ids and the images\n",
    "    for imagePath in path:\n",
    "        #loading the image and converting it to gray scale\n",
    "        pilImage=Image.open(imagePath).convert('L')\n",
    "        #Now we are converting the PIL image into numpy array\n",
    "        imageNp=np.array(pilImage,'uint8')\n",
    "        #getting the Id from the image\n",
    "        Id=int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        # extract the face from the training image sample\n",
    "        faces=facecascade.detectMultiScale(imageNp)\n",
    "        #If a face is there then append that in the list as well as Id of it\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(imageNp[y:y+h,x:x+w])\n",
    "            Ids.append(Id)\n",
    "    return faceSamples,Ids\n",
    "\n",
    "#Generate Data Button   \n",
    "b1=tk.Button(window,text=\"Generate Data\",font=(\"Arial\",16),bg='pink',fg='black',command=button)\n",
    "b1.grid(column=6,row=4)\n",
    "\n",
    "        \n",
    " #trainandrecog\n",
    "def recogbutton():\n",
    "    def draw_boundary(img,classifer,eyecascade,scaleFactor,minNeighbors,color,text,clf):\n",
    "        gray_image=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        features = classifer.detectMultiScale(gray_image,scaleFactor,minNeighbors)\n",
    "        coords=[]\n",
    "        gray_eyeimage=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        featureseye = eyecascade.detectMultiScale(gray_image,scaleFactor,minNeighbors)\n",
    "       \n",
    "        #fetching name\n",
    "        data_dir = \"data\";\n",
    "        path=[os.path.join(data_dir,f) for f in os.listdir(data_dir)]\n",
    "        user_name=[]\n",
    "        for imagePath in path:\n",
    "            #loading the image and converting it to gray scale\n",
    "            pilImage=Image.open(imagePath).convert('L')\n",
    "            #Now we are converting the PIL image into numpy array\n",
    "            imageNp=np.array(pilImage,'uint8')\n",
    "            #getting the Id from the image\n",
    "            user=os.path.split(imagePath)[-1].split(\".\")[0]\n",
    "            faces=facecascade.detectMultiScale(imageNp)\n",
    "            for (x,y,w,h) in faces:\n",
    "                user_name.append(user)\n",
    "        \n",
    "        for(x,y,w,h) in featureseye:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "        \n",
    "        for(x,y,w,h) in features:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "            idn,confidence= clf.predict(gray_image[y:y+h,x:x+w])\n",
    "            #confidence = int(100*(1-pred/300))\n",
    "\n",
    "            if (confidence > 90):\n",
    "                confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "                cv2.putText(img,str(user_name[idn]),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.8,color,1,cv2.LINE_AA)\n",
    "                cv2.putText(img, str(confidence),\n",
    "                            (x+5,y+h-5), cv2.FONT_HERSHEY_SIMPLEX,0.8, (255,255,0), 1) \n",
    "            else:\n",
    "                cv2.putText(img,\"UNKNOWN\",(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.8,color,1,cv2.LINE_AA)\n",
    "                cv2.putText(img, str(0),\n",
    "                            (x+5,y+h-5), cv2.FONT_HERSHEY_SIMPLEX,0.8, (255,255,0), 1) \n",
    "\n",
    "            coords=[x,y,w,h]\n",
    "        return  coords\n",
    "    def recognize(img,clf,facecascade,eyecascade):\n",
    "        coords= draw_boundary(img,facecascade,eyecascade,1.5,5,(255,255,255),\"Face\",clf)\n",
    "        return img\n",
    "   \n",
    "    recognizer .read(\"trainner.yml\") \n",
    "    if(recognizer==\"\"):\n",
    "        messagebox.showinfo(\"Empty Dataset\")\n",
    "    else:\n",
    "        video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "        while True:\n",
    "            ret,img = video_capture.read()\n",
    "            img = recognize(img,recognizer ,facecascade,eyecascade)\n",
    "            cv2.imshow(\"face Detection\",img)\n",
    "            if cv2.waitKey(1)==13:\n",
    "                break\n",
    "\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "#Recognize Button                \n",
    "b3=tk.Button(window,text=\"Recognize\",font=(\"Arial\",16),bg='pink',command= recogbutton)\n",
    "b3.grid(column=7,row=4)      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window.geometry(\"600x150\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
